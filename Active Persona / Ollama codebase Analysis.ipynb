{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35e28893-9419-42cc-96aa-31bb1bd5c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ollama\n",
    "from tqdm.notebook import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import concurrent.futures\n",
    "import humanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67dc1b7-dd8d-4fd4-b3df-e16c345e62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to configure\n",
    "config = {\n",
    "    \"directory\": r\"kt\",  # Codebase path\n",
    "    \"model\": \"llama3.2\",                        # Model of your choice\n",
    "    \"output\": \"code_analysis_results\",         # Output directory\n",
    "    \"max_size\": 5000,                          # Max characters per file to analyze\n",
    "    \"file_types\": [                            # File extensions to focus on\n",
    "       \".py\", \".java\", \".kt\", \".js\", \".ts\", \".c\", \n",
    "        \".cpp\", \".h\", \".cs\", \".html\", \".css\", \".xml\", \".resx\"\n",
    "    ],\n",
    "    \"num_workers\": 2,                          \n",
    "    \"skip_existing\": True,                    \n",
    "    \"sample_size\": None                    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dce70ecd-ad2b-4585-b8e6-d75b55e090c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going through the codebase\n",
    "def collect_code_files(directory_path, file_extensions, max_file_size=5000, sample_size=None):\n",
    "    \"\"\"Collect code files more efficiently\"\"\"\n",
    "    start_time = timer()\n",
    "    \n",
    "    print(f\"Scanning for files with extensions: {', '.join(file_extensions)}\")\n",
    "    \n",
    "    all_files = []\n",
    "    for ext in file_extensions:\n",
    "        all_files.extend(list(Path(directory_path).glob(f'**/*{ext}')))\n",
    "    \n",
    "    total_files = len(all_files)\n",
    "    print(f\"Found {total_files} matching files\")\n",
    "    \n",
    "    if sample_size and sample_size < total_files:\n",
    "        import random\n",
    "        all_files = random.sample(all_files, sample_size)\n",
    "        print(f\"Sampling {sample_size} files for analysis\")\n",
    "    \n",
    "    code_files = []\n",
    "    skipped_files = 0\n",
    "    \n",
    "    for file_path in tqdm(all_files, desc=\"Collecting files\"):\n",
    "        try:\n",
    "            file_size = file_path.stat().st_size\n",
    "            if file_size > max_file_size * 10:\n",
    "                skipped_files += 1\n",
    "                continue\n",
    "                \n",
    "            with open(file_path, 'r', encoding='utf-8', errors='replace') as f:\n",
    "                code = f.read()\n",
    "                if len(code) > max_file_size:\n",
    "                    code = code[:max_file_size] + \"\\n\\n// [TRUNCATED - file too large]\"\n",
    "                \n",
    "                if code.strip():\n",
    "                    code_files.append((str(file_path), code))\n",
    "        except Exception:\n",
    "            skipped_files += 1\n",
    "    \n",
    "    elapsed = timer() - start_time\n",
    "    print(f\"Successfully loaded {len(code_files)} files in {elapsed:.2f} seconds\")\n",
    "    print(f\"Skipped {skipped_files} files due to size or errors\")\n",
    "    \n",
    "    return code_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91c936c-9acb-418e-835b-ad7eebf7af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load persona from a text file\n",
    "with open(\"PersonaC.txt\", \"r\", encoding=\"utf-8\") as persona_file:\n",
    "    ux_persona = persona_file.read()\n",
    "\n",
    "# defined prompt with ollama\n",
    "def analyze_code_with_ollama(model_name, file_path, code):\n",
    "    \"\"\"Analyze a single code file using Ollama and return the analysis\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are {ux_persona}\n",
    "As an expert code reviewer, analyze this code from `{file_path}` evaluate the following case: This case investigates the compatibility of Bitwarden with Android 14. \n",
    "Animation stuttering and functionality failures were identified as issues on the latest OS version. Operate a codebase analysis to trace the potential cause of these issues.\n",
    "Important Instructions:\n",
    "- If the file is not related to the objective, skip it and donâ€™t write anything\n",
    "-only focus on the issue, no feedback on reliability, usability etc..\n",
    "\n",
    "CODE:\n",
    "{code}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = ollama.generate(model=model_name, prompt=prompt)\n",
    "        return response['response'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing code: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86571970-8624-437d-a9b5-df358a078a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a single file and save result\n",
    "def process_single_file(file_data, config, output_dir):\n",
    "    file_path, code = file_data\n",
    "    result_path = Path(output_dir) / (Path(file_path).name + \".md\")\n",
    "\n",
    "    if config[\"skip_existing\"] and result_path.exists():\n",
    "        return {\"skipped\": True}\n",
    "\n",
    "    analysis = analyze_code_with_ollama(config[\"model\"], file_path, code)\n",
    "    \n",
    "    try:\n",
    "        result_path.write_text(analysis, encoding=\"utf-8\")\n",
    "        return {\"skipped\": False}\n",
    "    except Exception as e:\n",
    "        return {\"skipped\": True, \"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d3b6d19-585d-4feb-a979-bc4c22f842ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process entire codebase\n",
    "def process_codebase(config):\n",
    "    overall_start_time = timer()\n",
    "    output_dir = Path(config[\"output\"])\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    code_files = collect_code_files(\n",
    "        config[\"directory\"], \n",
    "        config[\"file_types\"], \n",
    "        config[\"max_size\"],\n",
    "        config[\"sample_size\"]\n",
    "    )\n",
    "    \n",
    "    file_count = len(code_files)\n",
    "    analysis_results = []\n",
    "    \n",
    "    if file_count == 0:\n",
    "        print(\"No files to analyze!\")\n",
    "        return 0, output_dir\n",
    "    \n",
    "    print(f\"\\nStarting analysis of {file_count} files with {config['num_workers']} workers\")\n",
    "    analysis_start_time = timer()\n",
    "    \n",
    "    print(\"Analyzing first file to estimate total time...\")\n",
    "    sample_start = timer()\n",
    "    first_result = process_single_file(code_files[0], config, output_dir)\n",
    "    analysis_results.append(first_result)\n",
    "    sample_time = timer() - sample_start\n",
    "\n",
    "    estimated_total = sample_time * (file_count - 1) / config[\"num_workers\"]\n",
    "    print(f\"Estimated time for remaining files: {estimated_total:.2f} seconds ({estimated_total/60:.2f} minutes)\")\n",
    "\n",
    "    remaining_files = code_files[1:]\n",
    "    processed = 1\n",
    "    skipped = 1 if first_result.get(\"skipped\", False) else 0\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=config[\"num_workers\"]) as executor:\n",
    "        future_to_file = {\n",
    "            executor.submit(process_single_file, file_data, config, output_dir): file_data \n",
    "            for file_data in remaining_files\n",
    "        }\n",
    "        \n",
    "        with tqdm(total=len(remaining_files), desc=\"Analyzing files\") as pbar:\n",
    "            for future in concurrent.futures.as_completed(future_to_file):\n",
    "                result = future.result()\n",
    "                analysis_results.append(result)\n",
    "                processed += 1\n",
    "                if result.get(\"skipped\", False):\n",
    "                    skipped += 1\n",
    "                pbar.update(1)\n",
    "                \n",
    "                if processed % 5 == 0:\n",
    "                    elapsed = timer() - analysis_start_time\n",
    "                    rate = processed / elapsed\n",
    "                    remaining = (file_count - processed) / rate\n",
    "                    pbar.set_postfix({\"Remain\": humanize.naturaldelta(remaining), \"Skipped\": skipped})\n",
    "\n",
    "    analysis_time = timer() - analysis_start_time\n",
    "    total_time = timer() - overall_start_time\n",
    "\n",
    "    print(f\"\\nAnalysis running time:\")\n",
    "    print(f\"- Total  time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "    print(f\"- Analysis time: {analysis_time:.2f} seconds ({analysis_time/60:.2f} minutes)\")\n",
    "    print(f\"- TotalFiles analyzed: {file_count}\")\n",
    "    print(f\"- TotalFiles skipped: {skipped}\")\n",
    "    if file_count - skipped > 0:\n",
    "        print(f\"- Average time per file: {analysis_time/(file_count - skipped):.2f} seconds\")\n",
    "    else:\n",
    "        print(\"- No files analyzed .\")\n",
    "\n",
    "    return file_count, output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15719713-9f5d-4c47-a3ca-ee4ad2ca2044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting code quality analysis on: kt\n",
      "Using Ollama model: llama3.2\n",
      "Scanning for files with extensions: .py, .java, .kt, .js, .ts, .c, .cpp, .h, .cs, .html, .css, .xml, .resx\n",
      "Found 13 matching files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbf3da09e254a5fb2a8d632cb0f7070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 13 files in 0.03 seconds\n",
      "Skipped 0 files due to size or errors\n",
      "\n",
      "Starting analysis of 13 files with 2 workers\n",
      "Analyzing first file to estimate total time...\n",
      "Estimated time for remaining files: 128.32 seconds (2.14 minutes)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d6359caefe40a4a79d29b19441450c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize all .md files in one report\n",
    "def summarize_analysis_reports(output_dir, model_name=\"mistral\", summary_filename=\"summary_report.md\"):\n",
    "    md_files = list(Path(output_dir).rglob(\"*.md\"))\n",
    "    if not md_files:\n",
    "        print(\"Fail to summarize.\")\n",
    "        return\n",
    "\n",
    "    combined_content = \"\"\n",
    "    for md_file in md_files:\n",
    "        if md_file.name == summary_filename:\n",
    "            continue\n",
    "        try:\n",
    "            content = md_file.read_text(encoding=\"utf-8\")\n",
    "            combined_content += f\"\\n\\n### File: {md_file.name}\\n\\n{content}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {md_file}: {e}\")\n",
    "\n",
    "    summary_prompt = f\"\"\"\n",
    "You are a senior software quality analyst.\n",
    "\n",
    "Based on the following code analysis reports from multiple files, create a high-level summary.\n",
    "Important Instructions:\n",
    "\n",
    "Highlight:\n",
    "- strengths\n",
    "- Repeated weaknesses\n",
    "- Suggestions for overall improvement\n",
    "- if you found practical code example mentionned them (like their line and their location)\n",
    "-Avoid repeating file-level details unless relevant to the overall theme.\n",
    "### CODE ANALYSIS REPORTS:\n",
    "{combined_content}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = ollama.generate(model=model_name, prompt=summary_prompt)\n",
    "        summary = response[\"response\"].strip()\n",
    "        summary_path = Path(output_dir) / summary_filename\n",
    "        summary_path.write_text(summary, encoding=\"utf-8\")\n",
    "        print(f\"\\nSummary written to {summary_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "\n",
    "# Run analysis\n",
    "def run_analysis():\n",
    "    overall_start = timer()\n",
    "    \n",
    "    print(f\"Starting code quality analysis on: {config['directory']}\")\n",
    "    print(f\"Using Ollama model: {config['model']}\")\n",
    "    \n",
    "    file_count, output_dir = process_codebase(config)\n",
    "    \n",
    "    summarize_analysis_reports(output_dir, model_name=config[\"model\"])\n",
    "    \n",
    "    elapsed = timer() - overall_start\n",
    "    minutes, seconds = divmod(elapsed, 60)\n",
    "    \n",
    "    print(f\"\\nAnalysis complete in {int(minutes)} minutes, {seconds:.2f} seconds!\")\n",
    "    print(f\"Analyzed {file_count} files\")\n",
    "    print(f\"Results saved to: {output_dir}\")\n",
    "\n",
    "run_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
